import openai
from config import config
from cache_manager import analysis_cache

class GPTService:
    """GPT APIë¥¼ ì‚¬ìš©í•œ ì¥ë¥´ ì¶”ì²œ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.client = openai.OpenAI(api_key=config.openai_api_key)
    
    def get_genre_recommendation(self, title, artist):
        """ë…¸ë˜ ì œëª©ê³¼ ì•„í‹°ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¥ë¥´ ì¶”ì²œ"""
        try:
            prompt = f"ë…¸ë˜ ì œëª©ì´ '{title}', ì•„í‹°ìŠ¤íŠ¸ê°€ '{artist}'ì¸ MP3ì˜ ì¥ë¥´ë¥¼ ëŒ€ë¶„ë¥˜/ì§€ì—­/ìŠ¤íƒ€ì¼ í˜•ì‹ìœ¼ë¡œ ìµœëŒ€ 4ê°œê¹Œì§€ ì¶”ì²œí•´ì¤˜."
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ìŒì•…ì „ë¬¸ê°€ë¡œì„œ ë…¸ë˜ ì¥ë¥´ë¥¼ ì¶”ì²œí•´ì¤˜. ì ˆëŒ€ ê¸ˆì§€ ë‹¨ì–´: USA, America, American, India, Indian, Canada, Canadian, Japan, Japanese, China, Chinese, Korea, Korean, Britain, British, France, French, Germany, German, Australia, Australian, Nigeria, Nigeria, Ghana - ì´ëŸ° êµ­ê°€ëª…/êµ­ì  ë‹¨ì–´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ! í—ˆìš©ë˜ëŠ” ì§€ì—­ í‘œê¸°ëŠ” ì˜¤ì§ K-Pop, East Coast, West Coast, UK, Latinë§Œ ê°€ëŠ¥. í˜•ì‹: ëŒ€ë¶„ë¥˜/ì§€ì—­/ìŠ¤íƒ€ì¼ (ìµœëŒ€ 4ê°œ). ì˜ˆì‹œ 1:Hip Hop / East Coast / Trap, ì˜ˆì‹œ 2: Pop / Ballad ì˜ˆì‹œ 3: Rock / Alternative / Indie"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=100,
                temperature=0.4,
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            return f"GPT ì˜¤ë¥˜: {str(e)}"
    
    def _should_use_gpt4o(self, title, artist, year=None):
        """GPT-4o ì‚¬ìš© ì—¬ë¶€ ê²°ì • (ë¹„ìš© ìµœì í™”)"""
        # 1. ì—°ë„ ê¸°ë°˜ íŒë‹¨ (ê°€ì¥ ì •í™•í•œ ê¸°ì¤€)
        if year and year >= 2022:
            return True
        
        # 2. ìµœì‹  ì•„í‹°ìŠ¤íŠ¸ í‚¤ì›Œë“œ (ì—°ë„ ì •ë³´ê°€ ì—†ì„ ë•Œë§Œ)
        if not year:
            modern_keywords = [
                'newjeans', 'ive', 'aespa', 'itzy', 'stray kids', 'txt', 'enhypen',
                'billie eilish', 'olivia rodrigo', 'dua lipa', 'the weeknd',
                'bad bunny', 'rosalÃ­a', 'doja cat', 'lil nas x', 'ice spice'
            ]
            
            artist_lower = artist.lower()
            for keyword in modern_keywords:
                if keyword in artist_lower:
                    return True
        
        # 3. ê¸°ë³¸ê°’: GPT-3.5 ì‚¬ìš© (ë¹„ìš© ì ˆì•½)
        return False
    
    def _get_optimized_prompt(self, title, artist, use_web_search=True):
        """ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ìˆ˜ ì ˆì•½)"""
        if use_web_search:
            return f"""ì›¹ ê²€ìƒ‰ìœ¼ë¡œ '{title}' by {artist} ë¶„ì„:

í˜•ì‹:
â€¢ ëŒ€ë¶„ë¥˜: [ì¥ë¥´]
â€¢ ì§€ì—­: [ì§€ì—­]  
â€¢ ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼]
â€¢ ì¶œì²˜: [ì›¹ì‚¬ì´íŠ¸]

ğŸ“Œ ì •ë¦¬
â€¢ ëŒ€ë¶„ë¥˜: [ìµœì¢…]
â€¢ ì§€ì—­: [ìµœì¢…]
â€¢ ìŠ¤íƒ€ì¼: [ìµœì¢…]

ê¸ˆì§€ì–´: USA,America,American,India,Indian,Canada,Canadian,Japan,Japanese,China,Chinese,Korea,Korean,Britain,British,France,French,Germany,German,Australia,Australian
í—ˆìš©ì§€ì—­: K-Pop,East Coast,West Coast,UK,Latin"""
        else:
            return f"""'{title}' by {artist} ì¥ë¥´ ë¶„ì„:

â€¢ ëŒ€ë¶„ë¥˜: [ì¥ë¥´]
â€¢ ì§€ì—­: [ì§€ì—­]
â€¢ ìŠ¤íƒ€ì¼: [ìŠ¤íƒ€ì¼]

ğŸ“Œ ì •ë¦¬
â€¢ ëŒ€ë¶„ë¥˜: [ìµœì¢…]
â€¢ ì§€ì—­: [ìµœì¢…]  
â€¢ ìŠ¤íƒ€ì¼: [ìµœì¢…]

ê¸ˆì§€ì–´: USA,America,American,India,Indian,Canada,Canadian,Japan,Japanese,China,Chinese,Korea,Korean,Britain,British,France,French,Germany,German,Australia,Australian
í—ˆìš©ì§€ì—­: K-Pop,East Coast,West Coast,UK,Latin"""

    def get_detailed_genre_analysis(self, title, artist, year=None):
        """ë¹„ìš© ìµœì í™”ëœ ìƒì„¸í•œ ì¥ë¥´ ë¶„ì„"""
        try:
            # 1. ìºì‹œ í™•ì¸
            cached_result = analysis_cache.get_cached_analysis(title, artist)
            if cached_result:
                return f"ğŸ“‹ ìºì‹œëœ ê²°ê³¼:\n\n{cached_result}"
            
            # 2. ëª¨ë¸ ì„ íƒ (ë¹„ìš© ìµœì í™”)
            use_gpt4o = self._should_use_gpt4o(title, artist, year)
            model = "gpt-4o" if use_gpt4o else "gpt-3.5-turbo"
            
            # 3. í”„ë¡¬í”„íŠ¸ ìµœì í™”
            prompt = self._get_optimized_prompt(title, artist, use_gpt4o)
            
            # 4. API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ìŒì•… ì „ë¬¸ê°€. ê°„ê²°í•˜ê³  ì •í™•í•œ ì¥ë¥´ ë¶„ì„."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=400 if use_gpt4o else 300,  # í† í° ìˆ˜ ìµœì í™”
                temperature=0.3,
            )
            
            result = response.choices[0].message.content.strip()
            
            # 5. ê²°ê³¼ì— ëª¨ë¸ ì •ë³´ ì¶”ê°€
            model_info = f"\n\nğŸ¤– ë¶„ì„ ëª¨ë¸: {model.upper()}"
            if use_gpt4o:
                model_info += " (ì›¹ ê²€ìƒ‰ í¬í•¨)"
            else:
                model_info += " (ê¸°ì¡´ ì§€ì‹ ê¸°ë°˜)"
            
            final_result = result + model_info
            
            # 6. ìºì‹œì— ì €ì¥
            analysis_cache.save_analysis_to_cache(title, artist, final_result, model)
            
            return final_result
            
        except Exception as e:
            return f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
    


# ì „ì—­ GPT ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
gpt_service = GPTService() 